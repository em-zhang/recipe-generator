{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorial: https://medium.com/analytics-vidhya/nlp-word-prediction-by-using-bidirectional-lstm-9c01c24b2725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Lambda\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>start_ingredient</th>\n",
       "      <th>embedding_matrix_index_list</th>\n",
       "      <th>start_ingredient_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[beef, chicken_breast, cream_of_mushroom_soup,...</td>\n",
       "      <td>[[-0.33506337, 0.08803183, -0.24923237, 0.0341...</td>\n",
       "      <td>4</td>\n",
       "      <td>beef</td>\n",
       "      <td>[339, 1076, 1596, 5574]</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[peanut_butter, graham_cracker_crumb, butter, ...</td>\n",
       "      <td>[[-0.17900778, -0.039890748, -0.13081385, 0.30...</td>\n",
       "      <td>5</td>\n",
       "      <td>peanut_butter</td>\n",
       "      <td>[4375, 2733, 727, 4719, 1197]</td>\n",
       "      <td>4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[pineapple, condensed_milk, lemon, pecan, grah...</td>\n",
       "      <td>[[0.16943195, -0.31285393, -0.23219007, 0.1775...</td>\n",
       "      <td>5</td>\n",
       "      <td>pecan</td>\n",
       "      <td>[4519, 1412, 3479, 4401, 2735]</td>\n",
       "      <td>4401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[chicken, flour, barbecue_sauce]</td>\n",
       "      <td>[[-0.22679155, 0.100118645, 0.10348936, 0.2072...</td>\n",
       "      <td>3</td>\n",
       "      <td>barbecue_sauce</td>\n",
       "      <td>[1066, 2242, 297]</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[pie_filling, pineapple, condensed_milk, lemon...</td>\n",
       "      <td>[[-0.021126581, 0.1452302, -0.09510492, -0.035...</td>\n",
       "      <td>4</td>\n",
       "      <td>pie_filling</td>\n",
       "      <td>[4487, 4519, 1412, 3499]</td>\n",
       "      <td>4487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  NER  \\\n",
       "1   [beef, chicken_breast, cream_of_mushroom_soup,...   \n",
       "4   [peanut_butter, graham_cracker_crumb, butter, ...   \n",
       "9   [pineapple, condensed_milk, lemon, pecan, grah...   \n",
       "12                   [chicken, flour, barbecue_sauce]   \n",
       "14  [pie_filling, pineapple, condensed_milk, lemon...   \n",
       "\n",
       "                                           embeddings  num_ingredients  \\\n",
       "1   [[-0.33506337, 0.08803183, -0.24923237, 0.0341...                4   \n",
       "4   [[-0.17900778, -0.039890748, -0.13081385, 0.30...                5   \n",
       "9   [[0.16943195, -0.31285393, -0.23219007, 0.1775...                5   \n",
       "12  [[-0.22679155, 0.100118645, 0.10348936, 0.2072...                3   \n",
       "14  [[-0.021126581, 0.1452302, -0.09510492, -0.035...                4   \n",
       "\n",
       "   start_ingredient     embedding_matrix_index_list  start_ingredient_index  \n",
       "1              beef         [339, 1076, 1596, 5574]                     339  \n",
       "4     peanut_butter   [4375, 2733, 727, 4719, 1197]                    4375  \n",
       "9             pecan  [4519, 1412, 3479, 4401, 2735]                    4401  \n",
       "12   barbecue_sauce               [1066, 2242, 297]                     297  \n",
       "14      pie_filling        [4487, 4519, 1412, 3499]                    4487  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open and load data from pickle file\n",
    "file = open('../ner_embeddings.pkl', 'rb')\n",
    "\n",
    "# keys are strings for node_id, value is embedding\n",
    "embeddings_df = pickle.load(file)\n",
    "\n",
    "file.close()\n",
    "\n",
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    }
   ],
   "source": [
    "max_num_ing = embeddings_df['num_ingredients'].max()\n",
    "\n",
    "# 44 is the max number of ingredients\n",
    "print(max_num_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1076, 1596, 5574],\n",
       "       [   0,    0,    0, ...,  727, 4719, 1197],\n",
       "       [   0,    0,    0, ..., 3479, 4401, 2735],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  624, 3251, 2510],\n",
       "       [   0,    0,    0, ...,  727, 3822, 2998],\n",
       "       [   0,    0,    0, ..., 6471, 5228, 5601]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding the index lists to be 44 in length\n",
    "# using prepadding so that the last index will be the output\n",
    "input_sequences = np.array(pad_sequences(embeddings_df['embedding_matrix_index_list'], maxlen=max_num_ing, padding='pre'))\n",
    "\n",
    "input_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and load data from pickle file\n",
    "file = open('../FlavorGraph_NodeEmbedding.pickle', 'rb')\n",
    "\n",
    "# keys are strings for node_id, value is embedding\n",
    "data = pickle.load(file)\n",
    "\n",
    "file.close()\n",
    "\n",
    "# load dataframe of node_ids and ingredients\n",
    "df = pandas.read_csv('../nodes_191120.csv')\n",
    "# just get the embeddings for ingredients\n",
    "ing_embeddings = {}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'node_type'] == \"ingredient\":\n",
    "        # map the name of the ingredient to the embedding\n",
    "        ing_embeddings[df.loc[i, 'name']] = data[str(df.loc[i, 'node_id'])]\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10600116,  0.04714949,  0.10841199, ..., -0.03144248,\n",
       "        -0.06629407, -0.1286629 ],\n",
       "       [-0.01582931,  0.09736368, -0.00062261, ..., -0.09226537,\n",
       "        -0.12149926, -0.12204846],\n",
       "       [-0.10132008,  0.03372396,  0.06472784, ..., -0.22692445,\n",
       "        -0.04366636, -0.20344618],\n",
       "       ...,\n",
       "       [-0.19128327,  0.17544127, -0.09963894, ..., -0.20900002,\n",
       "        -0.17799097, -0.1547064 ],\n",
       "       [ 0.02008764,  0.04900858, -0.26409724, ..., -0.19495088,\n",
       "        -0.16633987, -0.21576235],\n",
       "       [ 0.20899913, -0.15171458, -0.25460058, ..., -0.18800448,\n",
       "        -0.08664556, -0.07758268]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open and load data from pickle file\n",
    "ner_embeddings_file = open('../ner_embeddings.pkl', 'rb')\n",
    "\n",
    "# keys are strings for node_id, value is embedding\n",
    "ner_embeddings = pickle.load(ner_embeddings_file)\n",
    "\n",
    "ner_embeddings_file.close()\n",
    "\n",
    "# probably could just run this and comment out the above, but I ran the training with the above\n",
    "# ner_embeddings = embeddings_df\n",
    "\n",
    "EMBEDDING_DIMENSIONS = 300\n",
    "\n",
    "# these indices are different from those in flavor graph\n",
    "matrix_ing_to_idx = {}\n",
    "idx_to_ing = {}\n",
    "\n",
    "def construct_embedding_matrix(embeddings):\n",
    "    num_ing = len(embeddings)\n",
    "\n",
    "    # initialize a matrix of zeros\n",
    "    # not adding a + 1 to num_ing because the data is cleaned such that only ones with valid ing are there\n",
    "    embedding_matrix = np.zeros((num_ing, EMBEDDING_DIMENSIONS)) # each embedding has 300 dimensions\n",
    "\n",
    "    next_row = 0\n",
    "\n",
    "    for i in embeddings:\n",
    "        v = embeddings.get(i)\n",
    "        embedding_matrix[next_row] = v\n",
    "        matrix_ing_to_idx[i] = next_row\n",
    "        idx_to_ing[next_row] = i\n",
    "        next_row+=1\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = construct_embedding_matrix(ing_embeddings)\n",
    "\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun up to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0, 2242, 5228, 1581, 6355, 1481, 2251],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sequences)\n",
    "input_subset = input_sequences[:10000]\n",
    "\n",
    "input_subset[9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will be the first 43, Y will be the last\n",
    "X, labels = input_subset[:,:-1],input_subset[:,-1]\n",
    "\n",
    "total_ing = 6653\n",
    "# converts to a classification problem, uses one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=total_ing)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6653"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorials for pre-trained embeddings\n",
    "https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
    "https://blog.paperspace.com/pre-trained-word-embeddings-natural-language-processing/\n",
    "https://medium.com/analytics-vidhya/nlp-word-prediction-by-using-bidirectional-lstm-9c01c24b2725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "# use pre-trained embeddings\n",
    "embedding_layer = Embedding(len(embedding_matrix),\n",
    "                            EMBEDDING_DIMENSIONS,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_num_ing-1, # -1 because last idx is y\n",
    "                            trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_ing, activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 54s 178ms/step - loss: 5.0331 - accuracy: 0.0895 - val_loss: 4.9989 - val_accuracy: 0.0840\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 4.6701 - accuracy: 0.1064 - val_loss: 4.9119 - val_accuracy: 0.1050\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 4.5121 - accuracy: 0.1210 - val_loss: 4.8355 - val_accuracy: 0.1185\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 4.3788 - accuracy: 0.1377 - val_loss: 4.7485 - val_accuracy: 0.1325\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 4.2405 - accuracy: 0.1552 - val_loss: 4.6911 - val_accuracy: 0.1480\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 4.1205 - accuracy: 0.1620 - val_loss: 4.6679 - val_accuracy: 0.1540\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 3.9968 - accuracy: 0.1721 - val_loss: 4.6525 - val_accuracy: 0.1455\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 3.8636 - accuracy: 0.1869 - val_loss: 4.6233 - val_accuracy: 0.1590\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 3.7348 - accuracy: 0.1964 - val_loss: 4.6228 - val_accuracy: 0.1690\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 52s 208ms/step - loss: 3.5971 - accuracy: 0.2138 - val_loss: 4.6162 - val_accuracy: 0.1735\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 3.4465 - accuracy: 0.2301 - val_loss: 4.6153 - val_accuracy: 0.1745\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 3.2997 - accuracy: 0.2494 - val_loss: 4.6619 - val_accuracy: 0.1805\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 3.1494 - accuracy: 0.2677 - val_loss: 4.7294 - val_accuracy: 0.1815\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 3.0006 - accuracy: 0.2890 - val_loss: 4.7147 - val_accuracy: 0.1895\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 2.8460 - accuracy: 0.3124 - val_loss: 4.7642 - val_accuracy: 0.1840\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 49s 194ms/step - loss: 2.6813 - accuracy: 0.3402 - val_loss: 4.8075 - val_accuracy: 0.1820\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 2.5218 - accuracy: 0.3806 - val_loss: 4.8284 - val_accuracy: 0.1865\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 2.3540 - accuracy: 0.4181 - val_loss: 4.9226 - val_accuracy: 0.1930\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 44s 178ms/step - loss: 2.1892 - accuracy: 0.4593 - val_loss: 4.9838 - val_accuracy: 0.1750\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 2.0313 - accuracy: 0.4979 - val_loss: 5.0776 - val_accuracy: 0.1840\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# callbacks = [\n",
    "#             EarlyStopping(patience = 10)\n",
    "#             ]\n",
    "num_epochs = 20\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 4.6015 - accuracy: 0.1809 - val_loss: 4.4304 - val_accuracy: 0.1955\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 3.9460 - accuracy: 0.2265 - val_loss: 4.3961 - val_accuracy: 0.2120\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 3.5955 - accuracy: 0.2564 - val_loss: 4.3891 - val_accuracy: 0.2020\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 3.3155 - accuracy: 0.2887 - val_loss: 4.4244 - val_accuracy: 0.1990\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 3.0553 - accuracy: 0.3216 - val_loss: 4.4628 - val_accuracy: 0.2065\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 2.8073 - accuracy: 0.3577 - val_loss: 4.4978 - val_accuracy: 0.2075\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 2.5674 - accuracy: 0.3950 - val_loss: 4.6081 - val_accuracy: 0.2000\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 2.3319 - accuracy: 0.4439 - val_loss: 4.6820 - val_accuracy: 0.2055\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 2.1053 - accuracy: 0.4944 - val_loss: 4.7584 - val_accuracy: 0.1945\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 1.8863 - accuracy: 0.5461 - val_loss: 4.8656 - val_accuracy: 0.1995\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 1.6751 - accuracy: 0.5972 - val_loss: 4.9426 - val_accuracy: 0.1895\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 1.4799 - accuracy: 0.6510 - val_loss: 5.0159 - val_accuracy: 0.1945\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 1.2927 - accuracy: 0.7053 - val_loss: 5.1702 - val_accuracy: 0.1865\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 1.1197 - accuracy: 0.7614 - val_loss: 5.3021 - val_accuracy: 0.1830\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.9693 - accuracy: 0.8000 - val_loss: 5.3787 - val_accuracy: 0.1845\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.8379 - accuracy: 0.8405 - val_loss: 5.5067 - val_accuracy: 0.1875\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.7161 - accuracy: 0.8719 - val_loss: 5.6494 - val_accuracy: 0.1680\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.5973 - accuracy: 0.9041 - val_loss: 5.7529 - val_accuracy: 0.1735\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.5302 - accuracy: 0.9145 - val_loss: 5.8391 - val_accuracy: 0.1690\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.4350 - accuracy: 0.9330 - val_loss: 5.9583 - val_accuracy: 0.1730\n"
     ]
    }
   ],
   "source": [
    "input_subset = input_sequences[10000: 20000]\n",
    "# X will be the first 43, Y will be the last\n",
    "X, labels = input_subset[:,:-1],input_subset[:,-1]\n",
    "\n",
    "total_ing = 6653\n",
    "# converts to a classification problem, uses one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=total_ing)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.20)\n",
    "    \n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 1.7696 - accuracy: 0.7063 - val_loss: 1.8184 - val_accuracy: 0.6915\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 1.2683 - accuracy: 0.7739 - val_loss: 1.8088 - val_accuracy: 0.6895\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 27s 110ms/step - loss: 0.9500 - accuracy: 0.8280 - val_loss: 1.8218 - val_accuracy: 0.6890\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.7382 - accuracy: 0.8634 - val_loss: 1.8707 - val_accuracy: 0.6615\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.5761 - accuracy: 0.8901 - val_loss: 1.9302 - val_accuracy: 0.6520\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.4547 - accuracy: 0.9154 - val_loss: 1.9815 - val_accuracy: 0.6340\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.3617 - accuracy: 0.9325 - val_loss: 2.0671 - val_accuracy: 0.6095\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.2944 - accuracy: 0.9465 - val_loss: 2.0901 - val_accuracy: 0.6135\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.2441 - accuracy: 0.9565 - val_loss: 2.1405 - val_accuracy: 0.5995\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.2103 - accuracy: 0.9620 - val_loss: 2.2554 - val_accuracy: 0.5820\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.2011 - accuracy: 0.9609 - val_loss: 2.3054 - val_accuracy: 0.5640\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.1872 - accuracy: 0.9632 - val_loss: 2.3366 - val_accuracy: 0.5530\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1620 - accuracy: 0.9668 - val_loss: 2.3692 - val_accuracy: 0.5565\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1435 - accuracy: 0.9668 - val_loss: 2.3993 - val_accuracy: 0.5400\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.1401 - accuracy: 0.9664 - val_loss: 2.4712 - val_accuracy: 0.5330\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.1522 - accuracy: 0.9615 - val_loss: 2.7462 - val_accuracy: 0.4705\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.3922 - accuracy: 0.9049 - val_loss: 2.7766 - val_accuracy: 0.4500\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.2608 - accuracy: 0.9426 - val_loss: 2.7796 - val_accuracy: 0.4725\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.1489 - accuracy: 0.9634 - val_loss: 2.6980 - val_accuracy: 0.4815\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.1105 - accuracy: 0.9682 - val_loss: 2.7485 - val_accuracy: 0.4875\n",
      "Epoch 1/20\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 5.0286 - accuracy: 0.1538 - val_loss: 4.4638 - val_accuracy: 0.1910\n",
      "Epoch 2/20\n",
      "250/250 [==============================] - 30s 122ms/step - loss: 3.8794 - accuracy: 0.2304 - val_loss: 4.4382 - val_accuracy: 0.1950\n",
      "Epoch 3/20\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 3.3697 - accuracy: 0.2994 - val_loss: 4.4915 - val_accuracy: 0.2010\n",
      "Epoch 4/20\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 2.9114 - accuracy: 0.3654 - val_loss: 4.5814 - val_accuracy: 0.1980\n",
      "Epoch 5/20\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 2.4997 - accuracy: 0.4331 - val_loss: 4.6879 - val_accuracy: 0.1900\n",
      "Epoch 6/20\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 2.1051 - accuracy: 0.5092 - val_loss: 4.7884 - val_accuracy: 0.2005\n",
      "Epoch 7/20\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 1.7389 - accuracy: 0.5926 - val_loss: 4.9428 - val_accuracy: 0.1970\n",
      "Epoch 8/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 1.4068 - accuracy: 0.6721 - val_loss: 5.1299 - val_accuracy: 0.1945\n",
      "Epoch 9/20\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 1.1165 - accuracy: 0.7564 - val_loss: 5.2448 - val_accuracy: 0.1915\n",
      "Epoch 10/20\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.8788 - accuracy: 0.8217 - val_loss: 5.3696 - val_accuracy: 0.1875\n",
      "Epoch 11/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.6802 - accuracy: 0.8764 - val_loss: 5.5583 - val_accuracy: 0.1895\n",
      "Epoch 12/20\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.5152 - accuracy: 0.9190 - val_loss: 5.6974 - val_accuracy: 0.1875\n",
      "Epoch 13/20\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.3934 - accuracy: 0.9446 - val_loss: 5.8298 - val_accuracy: 0.1870\n",
      "Epoch 14/20\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.3110 - accuracy: 0.9595 - val_loss: 5.9891 - val_accuracy: 0.1925\n",
      "Epoch 15/20\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.2487 - accuracy: 0.9647 - val_loss: 6.0976 - val_accuracy: 0.1895\n",
      "Epoch 16/20\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.2018 - accuracy: 0.9684 - val_loss: 6.2430 - val_accuracy: 0.1900\n",
      "Epoch 17/20\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1755 - accuracy: 0.9690 - val_loss: 6.3157 - val_accuracy: 0.1830\n",
      "Epoch 18/20\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1611 - accuracy: 0.9694 - val_loss: 6.4073 - val_accuracy: 0.1860\n",
      "Epoch 19/20\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1615 - accuracy: 0.9668 - val_loss: 6.4347 - val_accuracy: 0.1915\n",
      "Epoch 20/20\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.9699"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5b0d92de5dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1692\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                         )\n\u001b[0;32m-> 1694\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1695\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                         ):\n\u001b[1;32m   2039\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 10000\n",
    "while i < len(input_sequences):\n",
    "    input_subset = input_sequences[i: i+10000]\n",
    "    # X will be the first 43, Y will be the last\n",
    "    X, labels = input_subset[:,:-1],input_subset[:,-1]\n",
    "\n",
    "    total_ing = 6653\n",
    "    # converts to a classification problem, uses one-hot encoding\n",
    "    y = tf.keras.utils.to_categorical(labels, num_classes=total_ing)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.20)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\n",
    "    i+=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 4.7998 - accuracy: 0.1593 - val_loss: 4.3856 - val_accuracy: 0.1900\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 33s 134ms/step - loss: 3.8000 - accuracy: 0.2442 - val_loss: 4.3615 - val_accuracy: 0.2075\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 35s 140ms/step - loss: 3.2778 - accuracy: 0.3223 - val_loss: 4.4096 - val_accuracy: 0.2055\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 2.7856 - accuracy: 0.3909 - val_loss: 4.5512 - val_accuracy: 0.2125\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 2.3409 - accuracy: 0.4690 - val_loss: 4.6879 - val_accuracy: 0.2045\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 1.9157 - accuracy: 0.5571 - val_loss: 4.8542 - val_accuracy: 0.1995\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 1.5473 - accuracy: 0.6404 - val_loss: 4.9708 - val_accuracy: 0.2020\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 1.2141 - accuracy: 0.7306 - val_loss: 5.2062 - val_accuracy: 0.1990\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.9315 - accuracy: 0.8035 - val_loss: 5.3693 - val_accuracy: 0.1895\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.6985 - accuracy: 0.8679 - val_loss: 5.5211 - val_accuracy: 0.1965\n"
     ]
    }
   ],
   "source": [
    "input_subset = input_sequences[40000: 50000]\n",
    "# X will be the first 43, Y will be the last\n",
    "X, labels = input_subset[:,:-1],input_subset[:,-1]\n",
    "\n",
    "total_ing = 6653\n",
    "# converts to a classification problem, uses one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=total_ing)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.20)\n",
    "    \n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ingredients_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ingredients_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"ingredients_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(input_sequences)\n",
    "\n",
    "input_subset = input_sequences[540000: 550000]\n",
    "# X will be the first 43, Y will be the last\n",
    "X, labels = input_subset[:,:-1],input_subset[:,-1]\n",
    "\n",
    "total_ing = 6653\n",
    "# converts to a classification problem, uses one-hot encoding\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=total_ing)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model should be saved to ingredients_model, so you can rerun everything without retraining\n",
    "pre_trained = keras.models.load_model(\"ingredients_model\")\n",
    "\n",
    "ingredients_model = Sequential()\n",
    "\n",
    "for layer in pre_trained.layers[:-1]: # this is where I changed your code\n",
    "    ingredients_model.add(layer)    \n",
    "\n",
    "# Freeze the layers \n",
    "for layer in ingredients_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a scale from 1 to 99, how adventurous are you feeling? 1\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - 18s 62ms/step - loss: 6.8509 - accuracy: 0.1429 - val_loss: 6.6705 - val_accuracy: 0.1515\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 15s 59ms/step - loss: 6.3344 - accuracy: 0.1470 - val_loss: 6.4725 - val_accuracy: 0.1460\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 15s 60ms/step - loss: 5.9388 - accuracy: 0.1540 - val_loss: 6.3143 - val_accuracy: 0.1480\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 5.5984 - accuracy: 0.1590 - val_loss: 6.1973 - val_accuracy: 0.1470\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 5.2952 - accuracy: 0.1655 - val_loss: 6.1038 - val_accuracy: 0.1475\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 5.0267 - accuracy: 0.1727 - val_loss: 6.0373 - val_accuracy: 0.1450\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 15s 62ms/step - loss: 4.7882 - accuracy: 0.1791 - val_loss: 5.9819 - val_accuracy: 0.1530\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 4.5693 - accuracy: 0.1883 - val_loss: 5.9455 - val_accuracy: 0.1455\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 15s 62ms/step - loss: 4.3730 - accuracy: 0.1931 - val_loss: 5.9139 - val_accuracy: 0.1510\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 4.1911 - accuracy: 0.2026 - val_loss: 5.8979 - val_accuracy: 0.1470\n"
     ]
    }
   ],
   "source": [
    "# get user's input for temperature\n",
    "temp = float(input(\"On a scale from 1 to 99, how adventurous are you feeling? \"))\n",
    "temp = temp/100.0\n",
    "# flipping because higher temps should be more conservative\n",
    "temp = (temp * -1) + 1\n",
    "# print(temp)\n",
    "# add temp\n",
    "ingredients_model.add(Lambda(lambda x: x / temp))\n",
    "ingredients_model.add(pre_trained.layers[-1])\n",
    "\n",
    "ingredients_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = ingredients_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without the temp\n",
    "# ingredients_model = keras.models.load_model(\"ingredients_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ing_list(token_list, num_ing):\n",
    "    save = []\n",
    "\n",
    "    for _ in range(num_ing-1):\n",
    "        # after padding token_list will be 2D\n",
    "        token_list = pad_sequences([token_list], maxlen=max_num_ing-1, padding='pre', truncating='pre')\n",
    "\n",
    "        predicted = np.argmax(ingredients_model.predict(token_list), axis=-1)\n",
    "        \n",
    "        # back to 1D\n",
    "        token_list = np.append(token_list[0], predicted[0])\n",
    "\n",
    "    return token_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose your start ingredient(s), separated by a space: chocolate_chip potato_chip\n",
      "How many ingredients do you want? 17\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "chocolate_chip\n",
      "potato_chip\n",
      "peanut\n",
      "chinese_noodle\n",
      "chinese_noodle\n",
      "peanut\n",
      "raisin\n",
      "curry_powder\n",
      "honey\n",
      "mayonnaise\n",
      "salt\n",
      "pepper\n",
      "onion_salt\n",
      "raisin\n",
      "walnut\n",
      "raisin\n",
      "mayonnaise\n",
      "lemon_juice\n"
     ]
    }
   ],
   "source": [
    "start_ings = input(\"Choose your start ingredient(s), separated by a space: \")\n",
    "start_ing_list = start_ings.split(\" \")\n",
    "num_ing = int(input(\"How many ingredients do you want? \"))\n",
    "recipe_ingr = []\n",
    "\n",
    "token_list = []\n",
    "for ing in start_ing_list:\n",
    "    # convert to idx\n",
    "    ing_idx = matrix_ing_to_idx.get(ing, -1)\n",
    "    if ing_idx != -1:\n",
    "        token_list.append(ing_idx)\n",
    "    else:\n",
    "        print(\"Sorry, \"+ing+\" isn't in our ingredients list\")\n",
    "\n",
    "if len(token_list) > 0 and num_ing > 1:\n",
    "    token_list = predict_ing_list(token_list, num_ing)\n",
    "elif num_ing <= 1:\n",
    "    print(\"Too few ingredients--please select a higher number.\")\n",
    "elif num_ing < len(token_list):\n",
    "    print(\"You gave us more start ingredients than you want in your final recipe. Please try again.\")\n",
    "elif len(token_list) < 1:\n",
    "    print(\"Sorry, none of your ingredients are in our list. Try a different spelling or ingredient!\")\n",
    "    \n",
    "for idx in token_list:\n",
    "    if idx != 0:\n",
    "        recipe_ingr.append(idx_to_ing[idx])\n",
    "        print(idx_to_ing[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
